# 📑 4.6 — Health checks

Cette étape est le **dernier filet de sécurité** du workflow : elle vérifie que les services clés (Prometheus, Loki, Grafana) sont bien **démarrés et accessibles** après le déploiement.

---

## 🔹 Le step dans le workflow

```yaml
# ✅ Sanity checks rapides
- name: Health checks
  uses: appleboy/ssh-action@v1.0.0
  with:
    host: ${{ vars.SSH_HOST }}
    username: ${{ vars.SSH_USER }}
    password: ${{ secrets.SSH_PASSWORD }}
    port: 22
    script: |
      set -e
      echo "Prometheus:" && curl -sf http://localhost:9090/-/ready && echo " OK"
      echo "Loki:"       && curl -sf http://localhost:3100/ready   && echo " OK"
      echo "Grafana:"    && curl -sf http://localhost:3000/login   && echo " OK"
```

---

## 🔍 Décomposition ligne par ligne

### Sécurisation

* `set -e` : stoppe le script **au premier échec**.
  👉 Si un seul service n’est pas accessible, le job échoue immédiatement.

---

### Vérification Prometheus

```bash
curl -sf http://localhost:9090/-/ready && echo " OK"
```

* Endpoint `/ready` : fourni par Prometheus pour indiquer qu’il est **opérationnel**.
* `-s` = silencieux, `-f` = échoue si HTTP != 200.
* Si ça passe → affiche `OK`.
  👉 Permet de savoir si Prometheus est prêt à accepter des requêtes.

---

### Vérification Loki

```bash
curl -sf http://localhost:3100/ready && echo " OK"
```

* Loki expose également un endpoint `/ready`.
* Vérifie que l’**ingestion des logs** est fonctionnelle.
  👉 Sans ça, Grafana verrait bien la source, mais aucun log ne serait stocké.

---

### Vérification Grafana

```bash
curl -sf http://localhost:3000/login && echo " OK"
```

* Ici pas de `/ready`, donc on teste la page `/login`.
* Si Grafana répond avec HTTP 200, c’est qu’il est bien démarré et son serveur web tourne.
  👉 C’est une vérif basique mais suffisante.

---

## 🧠 Ce qu’on pourrait aussi ajouter

* **Healthcheck pour Fluent Bit**
  → pas d’API native, mais on peut vérifier si le port `2020` (HTTP server de Fluent Bit) répond.

  ```bash
  curl -sf http://localhost:2020 || echo "Fluent Bit KO"
  ```

* **Tester l’authentification Grafana** (si besoin)
  → simuler un login avec `curl -u admin:password`.
  Permet de vérifier que les **variables d’environnement sensibles** (user/password) sont bien prises en compte.

* **Sanity check des dashboards**
  → appeler l’API Grafana `/api/dashboards/home` avec un token admin pour confirmer que la DB et les dashboards sont chargés.

* **Vérifier les volumes**
  → s’assurer que les répertoires de persistance (Grafana, Prometheus, Loki) existent encore après un `down/up`.

* **Alertes en auto-test**
  → envoyer une fausse alerte (`amtool` pour Alertmanager, ou `curl` vers Grafana Alerting) afin de valider que la chaîne de notifications email fonctionne.

---

## ✅ TL;DR

* Ce step est un **test de fumée** (smoke test) : est-ce que les services critiques sont **UP et répondent correctement** ?
* Si l’un d’eux échoue → le workflow s’arrête → pas de déploiement “zombie”.
* On pourrait l’enrichir avec :

    * Vérif Fluent Bit
    * Vérif login Grafana
    * Vérif API Grafana dashboards/alertes
    * Test notification email

👉 C’est la **garantie minimale** que ton monitoring Sentinel est bien en vie après chaque push.

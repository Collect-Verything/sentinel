# 6.0 – Dépannage rapide 🚑

Même avec une pipeline bien rodée, certains problèmes peuvent bloquer le déploiement ou faire croire que la stack ne fonctionne pas. Voici un guide pratique pour diagnostiquer rapidement.

---

## 🔎 6.1 Debug listing (vérification des fichiers déployés)

**Symptôme :**
Après un `docker compose up`, Grafana ou Prometheus semblent fonctionner avec d’anciennes configs ou pas du tout.

**Cause probable :**
Les fichiers n’ont pas été correctement synchronisés depuis le repo → `/root/sentinel/` sur le serveur ne correspond pas au repo GitHub.

**Solution :**
Exécuter un `ls -la` sur le serveur pour vérifier le contenu :

```bash
ssh root@server
ls -la /root/sentinel
```

Vérifier que les fichiers modifiés en local sont bien présents.
👉 Si non, c’est que **l’étape Rsync a échoué** → relancer manuellement ou checker l’action GitHub.

---

## 🔄 6.2 Erreur `rsync`

**Symptôme :**
CI/CD échoue avec un message du type :

```
rsync: change_dir "sentinel" failed: No such file or directory
```

**Causes possibles :**

1. Le chemin du dossier `sentinel/` n’existe pas dans le repo.
2. Problème de credentials SSH (mot de passe / clé invalide).
3. Conflit de droits sur le serveur.

**Solutions :**

* Vérifier que le repo contient bien `sentinel/` à la racine.
* Corriger les secrets GitHub (`SSH_USER`, `SSH_PASSWORD`).
* Vérifier les droits sur `/root/sentinel` :

  ```bash
  ls -ld /root/sentinel
  ```

---

## 📊 6.3 Datasource Grafana manquante

**Symptôme :**
Dans Grafana, les dashboards affichent "Datasource not found".

**Causes possibles :**

* Le fichier `grafana/provisioning/datasources/datasource.yml` est absent ou mal écrit.
* Provisioning désactivé / mauvais chemin monté dans `docker-compose.yml`.
* Les datasources existantes sont encore en **base SQLite** (Grafana garde en DB même si le YAML est supprimé).
* Regarder 6.6 plus bas

**Solutions :**

1. Vérifier que le fichier YAML est bien copié dans le conteneur :

   ```bash
   docker exec -it grafana ls /etc/grafana/provisioning/datasources
   ```
2. Vérifier les logs Grafana pour une erreur de provisioning :

   ```bash
   docker logs grafana | grep provisioning
   ```
3. Si Grafana garde une ancienne datasource en DB → supprimer manuellement dans l’interface et redémarrer.

---

## 🚦 6.4 Services non *ready*

**Symptôme :**
Les checks retournent une erreur :

```
curl: (7) Failed to connect to localhost port 3100: Connection refused
```

**Causes possibles :**

* Service en crash (ex : Loki avec mauvaise config).
* Port déjà occupé sur le serveur.
* Container ne démarre pas faute de ressources (RAM, disque).

**Solutions :**

1. Inspecter l’état des conteneurs :

   ```bash
   docker compose ps
   ```
2. Lire les logs du conteneur fautif :

   ```bash
   docker logs loki
   docker logs prometheus
   ```
3. Vérifier que le port n’est pas utilisé :

   ```bash
   netstat -tulpn | grep 3100
   ```

---

## 📜 6.5 YAML provisioning non appliqué

**Symptôme :**
Un dashboard, une règle d’alerte ou un contact point défini en YAML n’apparaît pas dans Grafana.

**Causes possibles :**

* Erreur de syntaxe YAML (indentation, tabulation).
* Mauvais répertoire monté dans `docker-compose.yml`.
* Grafana a chargé le fichier mais l’a ignoré (ex : `apiVersion` manquant).

**Solutions :**

1. Vérifier les logs Grafana :

   ```bash
   docker logs grafana | grep error
   ```
2. Tester la validité YAML en local :

   ```bash
   yamllint grafana/provisioning/alerting/rules/nginx-rules.yml
   ```
3. Forcer un redémarrage Grafana pour recharger le provisioning.

---

## 📦 6.6 Volumes bindés et persistance des données

**Rôle des volumes bindés :**
Dans notre `docker-compose.yml`, plusieurs services utilisent des volumes **montés (bind)** pour persister ou échanger des données entre le host et les conteneurs.
Cela permet de :

* Conserver les données même après un `docker compose down`.
* Inspecter directement les fichiers depuis le serveur.
* Versionner uniquement la config YAML sans perdre les données runtime.

---

### 🔍 Volumes à surveiller

1. **Grafana**

    * Généralement monté sur `/var/lib/grafana` (persistance des dashboards, utilisateurs, alertes en DB SQLite).
    * ⚠️ Même si un fichier YAML de provisioning est supprimé, Grafana garde la datasource/alerte en DB.

   ```bash
   docker exec -it grafana ls /var/lib/grafana
   ```

2. **Prometheus**

    * Persiste ses métriques sur `/prometheus` ou `/var/lib/prometheus`.
    * Si ce volume est supprimé, toutes les métriques sont perdues.

   ```bash
   docker exec -it prometheus ls /prometheus
   ```

3. **Loki**

    * Peut stocker ses chunks et index dans `/loki`.
    * En mode simple, perte des logs si le volume est vidé.

   ```bash
   docker exec -it loki ls /loki
   ```

4. **Fluent Bit**

    * Utilise un bind vers `/var/lib/docker/containers/` et `/var/log/` pour lire les logs du host.
    * Si ce montage n’est pas présent, **aucun log n’arrivera dans Loki**.

   ```bash
   ls /var/lib/docker/containers/ | head
   ```

---

### 🚨 Problèmes fréquents liés aux volumes

* **Données persistantes malgré une nouvelle config**
  → Exemple : Grafana garde d’anciennes datasources en DB.
  ✅ Solution : vider ou recréer le volume si nécessaire.

* **Logs manquants dans Loki**
  → Souvent dû à un bind manquant (`/var/lib/docker/containers`).
  ✅ Vérifier les montages avec :

  ```bash
  docker inspect fluent-bit | grep Mounts -A 10
  ```

* **Disque saturé**
  → Prometheus et Loki stockent énormément de données.
  ✅ Nettoyer les volumes régulièrement si la rétention est trop longue.

---

### 💡 Bonnes pratiques

* Toujours documenter **où sont montés les volumes** dans le `compose.yml`.
* Utiliser des volumes Docker **nommés** (`volumes:`) plutôt que des chemins absolus quand possible.
* Pour tester une nouvelle config : **ne pas supprimer les volumes bindés** si on veut garder l’historique.
* Pour repartir à zéro : faire un

  ```bash
  docker compose down -v
  ```

---


## ✅ Bonnes pratiques de dépannage

* Toujours commencer par un `docker compose ps` + `docker logs` pour voir l’état réel.
* Ajouter des **`echo` clairs dans les scripts CI/CD** pour suivre les étapes.
* En cas de doute sur Grafana : supprimer son volume (⚠️ pertes dashboards manuels) pour forcer un reset provisioning.
* Garder des **dashboards JSON exportés** versionnés dans le repo (comme `products-logs.json`).

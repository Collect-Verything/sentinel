# ğŸ“˜ Fiche â€“ Prometheus (`prometheus.yml` avec Sentinel & Product)


**AVANT LECTURE, LIRE AVANT-PROPOS DANS :** -> documentation/lire-avant-de-rentrer-dans-la-doc.md

---

## ğŸ¯ RÃ´le de Prometheus

Prometheus est **le collecteur central de mÃ©triques** dans Sentinel.
Il se connecte aux **exporters** (par ex. Node Exporter) dÃ©ployÃ©s sur les serveurs (Sentinel et Product) pour rÃ©cupÃ©rer pÃ©riodiquement des informations systÃ¨me :

* CPU, mÃ©moire, disque
* RÃ©seau, sockets, IO
* Uptime, load average

ğŸ‘‰ Ces mÃ©triques alimentent **Grafana** (dashboards) et **Grafana Alerting** (alertes).

---

## ğŸ“‚ Localisation

Le fichier `prometheus.yml` est dans :

```
sentinel/
â”œâ”€â”€ prometheus.yml   # Config Prometheus
```

Et est montÃ© dans le conteneur Prometheus via `docker-compose.yml`.

---

## ğŸ“‘ Contenu actuel

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]

  - job_name: "sentinel-node"
    static_configs:
      - targets: ["82.165.92.40:9100"]

  - job_name: "product-node"
    static_configs:
      - targets: ["82.165.46.201:9100"]
```

---

## ğŸ” Explication dÃ©taillÃ©e

### Bloc `global`

* **`scrape_interval: 15s`**

    * Toutes les 15 secondes, Prometheus interroge ses cibles (`targets`) pour collecter les mÃ©triques.
    * âš–ï¸ Bon compromis entre prÃ©cision et charge systÃ¨me.

* **`evaluation_interval: 15s`**

    * Toutes les 15 secondes, Prometheus Ã©value les rÃ¨gles dâ€™alerte (si elles sont dÃ©finies).
    * Exemple futur : "si CPU > 90% sur Product pendant 5 minutes, dÃ©clencher une alerte".

---

### Bloc `scrape_configs`

Chaque bloc dÃ©finit un **job** (= un groupe de targets homogÃ¨nes).

#### 1. `job_name: "prometheus"`

* **Cible : `localhost:9090`**
* RÃ´le : Prometheus se surveille lui-mÃªme.
* Utile pour :

    * VÃ©rifier quâ€™il scrape bien.
    * Avoir un dashboard "Health Prometheus".
    * DÃ©tecter sâ€™il est surchargÃ© ou tombe en panne.

ğŸ‘‰ Câ€™est de lâ€™**auto-monitoring**.

---

#### 2. `job_name: "sentinel-node"`

* **Cible : `82.165.92.40:9100`** (ton serveur Sentinel).
* Cela correspond au **Node Exporter** qui tourne sur Sentinel.
* Permet de :

    * Monitorer les ressources systÃ¨me du serveur Sentinel (CPU, RAM, disque, rÃ©seau).
    * DÃ©tecter si Sentinel est saturÃ© ou tombe (important car câ€™est le serveur de monitoring).
* Futur :

    * CrÃ©er une alerte "Sentinel down".
    * VÃ©rifier la santÃ© de lâ€™infra de monitoring elle-mÃªme.

---

#### 3. `job_name: "product-node"`

* **Cible : `82.165.46.201:9100`** (ton serveur Product).
* Cela correspond au **Node Exporter** installÃ© sur Product.
* Permet de :

    * Suivre les ressources systÃ¨me du serveur applicatif (oÃ¹ ton produit tourne).
    * CorrÃ©ler les mÃ©triques systÃ¨me avec les logs applicatifs (via Fluent Bit + Loki).
* Futur :

    * Alerte si Product manque de RAM/disque.
    * Dashboard spÃ©cifique Product (CPU par process, utilisation mÃ©moire, erreurs rÃ©seau).

---

## ğŸ“Š Exemple dâ€™utilisation dans Grafana

* Query PromQL pour voir lâ€™utilisation CPU sur Product :

```promql
rate(node_cpu_seconds_total{job="product-node", mode="user"}[5m])
```

* Query PromQL pour voir lâ€™espace disque restant sur Sentinel :

```promql
node_filesystem_avail_bytes{job="sentinel-node"} / node_filesystem_size_bytes{job="sentinel-node"}
```

ğŸ‘‰ Ces queries sont utilisÃ©es dans les dashboards comme **Node Exporter Full (1860)**.

---

## âš ï¸ ProblÃ¨mes courants

1. **Exporter inaccessible**

    * Si `82.165.46.201:9100` est fermÃ© par firewall â†’ pas de mÃ©triques Product.
    * VÃ©rifier avec :

      ```bash
      curl http://82.165.46.201:9100/metrics
      ```

2. **Targets incorrectes**

    * En Docker Compose, utiliser les **noms de service** (`node-exporter:9100`) plutÃ´t quâ€™une IP directe.
    * Pour des serveurs externes comme Product â†’ OK dâ€™utiliser IP.

3. **Scrape interval trop court**

    * < 15s surcharge la DB et les serveurs.
    * 15â€“30s recommandÃ©.

---

## ğŸ’¡ Bonnes pratiques futures

* **Nommer les jobs de maniÃ¨re cohÃ©rente**
  Ex : `sentinel-node`, `product-node`, `db-node`, `cache-node`â€¦
* **Groupes dâ€™instances**
  On peut mettre plusieurs targets dans un job, par ex :

  ```yaml
  - job_name: "product-nodes"
    static_configs:
      - targets:
          - "82.165.46.201:9100"
          - "82.165.46.202:9100"
  ```
* **Relabelling**
  Ajouter des labels (`env=prod`, `env=dev`) pour filtrer facilement dans Grafana.
* **Exporter dâ€™applications**
  Plus tard, tu pourras ajouter des exporters spÃ©cifiques :

    * MySQL exporter (DB metrics).
    * Nginx exporter (requÃªtes HTTP).
    * Redis exporter.

---

## ğŸ§­ RÃ©sumÃ©

* `prometheus.yml` = **liste des serveurs Ã  surveiller** via Node Exporter.
* Actuellement, tu surveilles :

    * Prometheus lui-mÃªme.
    * Sentinel (ton serveur de monitoring).
    * Product (ton serveur applicatif).
* Cela permet dÃ©jÃ  :

    * De voir si Product tourne bien.
    * Dâ€™avoir des alertes sur Product et Sentinel.
* Futur :

    * Ajouter dâ€™autres services (DB, cache, APIâ€¦).
    * CrÃ©er des rÃ¨gles dâ€™alertes ciblÃ©es (ex. Product saturÃ© = mail).
